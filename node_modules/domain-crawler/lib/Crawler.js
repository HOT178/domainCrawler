var http = require('http'),
	superagent = require('superagent'),
	cheerio = require('cheerio'),
	promise = require('promise'),
	fs = require('fs'),
	_ = require('underscore'),
	utils = require('./utils');
	processbar = require('./processbar')

var RECORD_PATH = "./result.txt",
	OUT_CONTENT = "all",
	MAX_DEPTH = 2,
	MAX_SOCKET = 3000;

var index = 0,
	all = 0,
	domain_array = [],
	bar = new processbar();

var out = [];

// Crawler构造函数
// 改为支持两种方法，一种是直接cheerio进行爬取，一种直接分析文本，匹配得到（研究下稳定的正则）
// 改为当前页面或者多级爬取页面，例如设置爬取带有" baidu "字符子串的url
// 

var Crawler = function(config, c) {

	var self = this;

	config = self.config = config;
	out = config.out;
	MAX_DEPTH = config['depth'] || MAX_DEPTH;
	OUT_CONTENT = config.out['content'] || OUT_CONTENT;
	RECORD_PATH = config.out['path'] || RECORD_PATH;

	utils.cleanFile(RECORD_PATH); 	

	return self;
};


_.extend(Crawler.prototype, {

	// Crawler需要保持静态，可以内部再维护一个crawler
	/**
	 * 从目标网址上爬取存在的域名，默认是采用cheerio获取DOM树，并从树中找出含有src属性的元素收集起来
	 */
	crawl : function(url, depth) {

		// 这个好像会很大，所以需要做清理操作
		// 模块内部定义的全局是属于模块域下的

		depth = depth || (0);
		depth++;

		if(depth > MAX_DEPTH) return;

		var self = this;
		
		all++;

		var load_html_promise = new promise(function(resolve, reject) {

			http.get(url, function(res) {
				var html = '';
				res.on('data', function(data) {
					html += data;
				});
				res.on('end', function() {
					resolve(cheerio.load(html));
				});
				res.on('error', function(e) {
					reject(e.message);
				})
			});
		});

		// document代表当前爬取文档
		load_html_promise.then(function(document) {

			if(!document("a")[0]) return 0;

			var tt = self.getTags(document);
			var tags = tt['tags'];
			var urls = tt['urls'];

			index++;

			if(index > MAX_SOCKET) {
				bar.complete();
				return 0;
			}	

			for(var i in out) {

				var path = out[i]['path'],
					content = out[i]['content'];

				if (content === 'all') {
					var uni_domain_list_str = utils.array2ListStr(self.getUniqueDomains(self.getDomains(urls)));
					utils.appendFile(path, uni_domain_list_str, "去重domains : index; " + index + " from : " + url + " ");
				} else {
					domain_array = self.getUniqueDomains(domain_array.concat(self.getUniqueDomains(self.getDomains(urls))));
					utils.cleanFile(path); 
					var uni_domain_list_str = utils.array2ListStr(domain_array);
					utils.appendFile(path, uni_domain_list_str, "去重domains : ");
				}
			}

			

			bar.update(index, all, "Crawling depth of " + depth);

			for(var i in tags) {
				var href = tags[i].attribs.href;
				if(utils.filterLvDomain(href) && utils.filterDomain(href)) {
					self.crawl(href, depth);
				}
			};
			return 0;
		});
		
		return 0;
	},

	getAttrDomain : function (attrs) {
		for(var i in attrs) {
			var elements = utils.traverseDom($("html")[0], attrs[i]); 
		}
	},

	getCommentDomain : function () {

		var comments = utils.traverseDom($("html")[0], "comment"); 

		var domains = [];
		
		// !
		var reg = /(http|https):\/\/([^\/]+)\//ig;
		(function(){
			for (var i in comments) {
				var result = comments[i]["nodeValue"].match(reg);
				if(result) {
					for(var j in result) {
						domains.push(result[j].split("/")[2]);
					}
				}
			}
		})();
		return domains;
	},

	getInlineDomain : function() {
		var inlinescripts = utils.getTagArray("script").filter(function(item){
			if(item.src === "") { return true; }
			else { return false; }
		});

		var reg = /(http|https):\/\/([^\/]+)\//ig;
		var result = [];
		for(var i in inlinescripts) {
			var matchedDomain = inlinescripts[i].innerHTML.match(reg);
			if(matchedDomain) {
				// 需要遍历
				var domain = (inlinescripts[i].innerHTML.match(reg))[0].split("/")[2];
				result.push(domain);
			}
		}
		return result;
	},

	getTags : function(document) {

		var self = this;
		var tag_map = self.config["tag"];

		var tags = [];
		var urls = [];

		for(var key in tag_map) {
			var tagName = key;
			var attr = tag_map[key];

			if(typeof(attr) !== "string") {
				for(var i in attr) {
					setTags(tagName, attr[i]);
				}
			} else {
				setTags(tagName, attr);
			}
		};

		// 需要缩减
		function setTags (tagName, attr) {

			tags = tags.concat(utils.getTagArray(document, tagName).filter(function(t){
				return t.attribs[attr] && t.attribs[attr] !== "";
			}));


			// 性能
			tags = _.filter(tags, function(t) {
				return utils.filterDomain(t.attribs[attr]);
			});

			urls = urls.concat((function(t){
				var urls = [];
				for(var i in t) {
					urls.push(tags[i]["attribs"][attr]);
				}
				return urls;
			})(tags));

		};

		return {'tags' : tags, 'urls' : urls};
	},

	// 获得一个以域组成的数组
	getDomains : function(urls) {

		var domains = [];

		for(var i in urls) {
			var domain = urls[i].split("/")[2];
			if(domain) domains.push(domain);
		};

		return domains;
	},

	getUniqueDomains : function (domains) {

		return utils.unique(domains);
	}

});

module.exports = Crawler;
